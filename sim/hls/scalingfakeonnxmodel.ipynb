{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import TensorProto\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is:\n",
      "ir_version: 9\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X_0\"\n",
      "    input: \"weight_0\"\n",
      "    output: \"XMM32_0\"\n",
      "    name: \"mm_0\"\n",
      "    op_type: \"MatMulInteger\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMM32_0\"\n",
      "    input: \"bias_0\"\n",
      "    output: \"XMMB32_0\"\n",
      "    name: \"add_0\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMMB32_0\"\n",
      "    output: \"XMMB8_0\"\n",
      "    op_type: \"Cast\"\n",
      "    attribute {\n",
      "      name: \"to\"\n",
      "      i: 3\n",
      "      type: INT\n",
      "    }\n",
      "  }\n",
      "  node {\n",
      "    input: \"XMMB8_0\"\n",
      "    output: \"Y_0\"\n",
      "    name: \"relu_0\"\n",
      "    op_type: \"Relu\"\n",
      "  }\n",
      "  name: \"testmodel_0\"\n",
      "  initializer {\n",
      "    dims: 8\n",
      "    dims: 8\n",
      "    data_type: 3\n",
      "    name: \"weight_0\"\n",
      "    raw_data: \"\\022\\326D\\005p\\332\\204\\227r.\\322F\\351:i\\031\\242\\252J\\261$\\363\\333`\\233\\265\\374&\\202\\022\\txw\\334\\274\\332\\000\\302A\\225\\347>\\2307\\374\\226v\\346\\311\\323\\363F\\035\\260\\n \\312\\312d\\260\\013\\266,\\002\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 8\n",
      "    data_type: 6\n",
      "    name: \"bias_0\"\n",
      "    raw_data: \"\\270\\377\\377\\377\\230\\377\\377\\377\\375\\377\\377\\377\\367\\377\\377\\377\\016\\000\\000\\000b\\000\\000\\000\\034\\000\\000\\000\\370\\377\\377\\377\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X_0\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 3\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 8\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y_0\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 3\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 8\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 19\n",
      "}\n",
      "\n",
      "The model is checked!\n"
     ]
    }
   ],
   "source": [
    "def make_layer(in_dim, out_dim, idx):\n",
    "    # Create one input (ValueInfoPro    to)\n",
    "    X = helper.make_tensor_value_info(f\"X_{idx}\", TensorProto.INT8, [in_dim])\n",
    "    w = helper.make_tensor(f\"weight_{idx}\", TensorProto.INT8, [out_dim, in_dim], np.random.randint(-128, 128, (out_dim, in_dim)).astype(np.int8).tobytes(), raw=True)\n",
    "    b = helper.make_tensor(f\"bias_{idx}\", TensorProto.INT32, [out_dim], np.random.randint(-128, 128, (out_dim)).astype(np.int32).tobytes(),  raw=True)\n",
    "\n",
    "    # Create one output (ValueInfoProto)\n",
    "    Y = helper.make_tensor_value_info(f\"Y_{idx}\", TensorProto.INT8, [out_dim])\n",
    "\n",
    "    mmnode = helper.make_node(\n",
    "        \"MatMulInteger\",\n",
    "        [f\"X_{idx}\", f\"weight_{idx}\"],\n",
    "        [f\"XMM32_{idx}\"],\n",
    "        name=f\"mm_{idx}\"\n",
    "    )\n",
    "\n",
    "    biasnode = helper.make_node(\n",
    "        \"Add\",\n",
    "        [f\"XMM32_{idx}\", f\"bias_{idx}\"],\n",
    "        [f\"XMMB32_{idx}\"],\n",
    "        name=f\"add_{idx}\"\n",
    "    )\n",
    "\n",
    "    castnode = helper.make_node( #FIXME: cast truncates bits\n",
    "        \"Cast\",\n",
    "        [f\"XMMB32_{idx}\"],\n",
    "        [f\"XMMB8_{idx}\"],\n",
    "        to=TensorProto.INT8\n",
    "    )\n",
    "\n",
    "    relunode = helper.make_node(\n",
    "        \"Relu\",\n",
    "        [f\"XMMB8_{idx}\"],\n",
    "        [f\"Y_{idx}\"],\n",
    "        name=f\"relu_{idx}\"\n",
    "    )\n",
    "\n",
    "    # Create the graph (GraphProto)\n",
    "    graph_def = helper.make_graph(\n",
    "        [mmnode,  biasnode, castnode, relunode],\n",
    "        f\"testmodel_{idx}\",\n",
    "        [X],\n",
    "        [Y],\n",
    "        [w, b]\n",
    "    )\n",
    "\n",
    "    # Create the model (ModelProto)\n",
    "    opset = onnx.OperatorSetIdProto()\n",
    "    opset.version = 19\n",
    "    return helper.make_model(graph_def, opset_imports = [opset])\n",
    "\n",
    "model_def = make_layer(8, 8, 0)\n",
    "print(f\"The model is:\\n{model_def}\")\n",
    "onnx.checker.check_model(model_def)\n",
    "onnx.shape_inference.infer_shapes(model_def, check_type=True, strict_mode=True, data_prop=True)\n",
    "print(\"The model is checked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 12, 40, 60, 126, 168, 288, 360, 550]\n",
      "[110, 132, 156, 182, 210, 240, 272, 306, 342, 380, 420, 462, 506, 552, 600, 650, 702, 756, 812, 870, 930, 992, 1056, 1122, 1190, 1260, 1332, 1406, 1482, 1560, 1640, 1722, 1806, 1892, 1980, 2070, 2162, 2256, 2352, 2450, 2550, 2652, 2756, 2862, 2970, 3080, 3192, 3306, 3422, 3540, 3660, 3782, 3906, 4032, 4160, 4290, 4422, 4556, 4692, 4830, 4970, 5112, 5256, 5402, 5550, 5700, 5852, 6006, 6162, 6320, 6480, 6642, 6806, 6972, 7140, 7310, 7482, 7656, 7832, 8010, 8190, 8372, 8556, 8742, 8930, 9120, 9312, 9506, 9702, 9900, 10100, 10302, 10506, 10712, 10920, 11130, 11342, 11556, 11772, 11990, 12210, 12432, 12656, 12882, 13110, 13340, 13572, 13806, 14042, 14280, 14520, 14762, 15006, 15252, 15500, 15750, 16002, 16256, 16512, 16770, 17030, 17292, 17556, 17822, 18090, 18360, 18632, 18906, 19182, 19460, 19740, 20022, 20306, 20592, 20880, 21170, 21462, 21756, 22052, 22350, 22650, 22952, 23256, 23562, 23870, 24180, 24492, 24806, 25122, 25440, 25760, 26082, 26406, 26732, 27060, 27390, 27722, 28056, 28392, 28730, 29070, 29412, 29756, 30102, 30450, 30800, 31152, 31506, 31862, 32220, 32580, 32942, 33306, 33672, 34040, 34410, 34782, 35156, 35532, 35910, 36290, 36672, 37056, 37442, 37830, 38220, 38612, 39006, 39402, 39800, 40200, 40602, 41006, 41412, 41820, 42230, 42642, 43056, 43472, 43890, 44310, 44732, 45156, 45582, 46010, 46440, 46872, 47306, 47742, 48180, 48620, 49062, 49506, 49952, 50400, 50850, 51302, 51756, 52212, 52670, 53130, 53592, 54056, 54522, 54990, 55460, 55932, 56406, 56882, 57360, 57840, 58322, 58806, 59292, 59780, 60270, 60762, 61256, 61752, 62250]\n"
     ]
    }
   ],
   "source": [
    "def make_multilayer(n_layers, layer_widths = None):\n",
    "    if layer_widths == None:\n",
    "        layer_widths = [n_layers for _ in range(2*n_layers)]\n",
    "    layers = [make_layer(layer_widths[2*i], layer_widths[2*i+1], i) for i in range(n_layers)]\n",
    "    n_params = sum(layer_widths[2*i]*layer_widths[2*i + 1] + layer_widths[2*i+1] for i in range(n_layers//2))\n",
    "    model = layers[0]\n",
    "    for idx, l in enumerate(layers[1:-1]):\n",
    "        model = onnx.compose.merge_models(model, l, [(f\"Y_{idx}\", f\"X_{idx+1}\")])\n",
    "    if n_layers > 1:\n",
    "        model = onnx.compose.merge_models(model, layers[-1], [(f\"Y_{n_layers-2}\", f\"X_{n_layers-1}\")])\n",
    "    return model, n_params\n",
    "print([make_multilayer(i)[1] for i in range(2, 11)])\n",
    "onnx.checker.check_model(make_multilayer(3)[0])\n",
    "print(list(make_multilayer(3, [N, N, N, N, N, N, N])[1] for N in range(10, 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating\n"
     ]
    }
   ],
   "source": [
    "from compiler import parsemodel, fpgamodule\n",
    "WIDTH = 4\n",
    "DEPTH = 3\n",
    "onnx_model = make_multilayer(DEPTH, [WIDTH for i in range(2*DEPTH + 1)])[0]\n",
    "spec = fpgamodule.FPGASpec(120, 600_000, 2_700_000, 100_000)\n",
    "fpga_module = parsemodel.parse_model(onnx_model, WIDTH, spec)\n",
    "fpga_module.alloc_regs()\n",
    "fpga_module.alloc_bram()\n",
    "sv = fpga_module.make_sv()\n",
    "with open(\"dummy_model.sv\", \"w\") as f:\n",
    "    f.write(sv)\n",
    "print(\"done generating\")\n",
    "onnx.save(onnx_model, \"testmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      " +C weight_0: int8:(4, 4):-83,-118,-2,22,93...\n",
      " +C bias_0: int32:(4,):[-58, -69, 30, -79]\n",
      " +C weight_1: int8:(4, 4):82,125,24,8,-113...\n",
      " +C bias_1: int32:(4,):[102, 75, 103, -67]\n",
      " +C weight_2: int8:(4, 4):29,67,-63,-127,-15...\n",
      " +C bias_2: int32:(4,):[-73, -89, 28, -85]\n",
      " +I X_0: int8:(4,):[1, 1, 1, 1]\n",
      "MatMulInteger(X_0, weight_0) -> XMM32_0\n",
      " + XMM32_0: int32:(4,):[235, -296, 78, 74]\n",
      "Add(XMM32_0, bias_0) -> XMMB32_0\n",
      " + XMMB32_0: int32:(4,):[177, -365, 108, -5]\n",
      "Cast(XMMB32_0) -> XMMB8_0\n",
      " + XMMB8_0: int8:(4,):[-79, -109, 108, -5]\n",
      "Relu(XMMB8_0) -> Y_0\n",
      " + Y_0: int8:(4,):[0, 0, 108, 0]\n",
      "MatMulInteger(Y_0, weight_1) -> XMM32_1\n",
      " + XMM32_1: int32:(4,):[-12744, -6696, 432, 10152]\n",
      "Add(XMM32_1, bias_1) -> XMMB32_1\n",
      " + XMMB32_1: int32:(4,):[-12642, -6621, 535, 10085]\n",
      "Cast(XMMB32_1) -> XMMB8_1\n",
      " + XMMB8_1: int8:(4,):[-98, 35, 23, 101]\n",
      "Relu(XMMB8_1) -> Y_1\n",
      " + Y_1: int8:(4,):[0, 35, 23, 101]\n",
      "MatMulInteger(Y_1, weight_2) -> XMM32_2\n",
      " + XMM32_2: int32:(4,):[-560, 6973, 2554, 2275]\n",
      "Add(XMM32_2, bias_2) -> XMMB32_2\n",
      " + XMMB32_2: int32:(4,):[-633, 6884, 2582, 2190]\n",
      "Cast(XMMB32_2) -> XMMB8_2\n",
      " + XMMB8_2: int8:(4,):[-121, -28, 22, -114]\n",
      "Relu(XMMB8_2) -> Y_2\n",
      " + Y_2: int8:(4,):[0, 0, 22, 0]\n",
      "[array([ 0,  0, 22,  0], dtype=int8)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "from onnx.reference import ReferenceEvaluator\n",
    "\n",
    "providers = [\"CPUExecutionProvider\"]\n",
    "print(ort.get_available_providers())\n",
    "options = ort.SessionOptions()\n",
    "options.enable_profiling=False\n",
    "sess = ReferenceEvaluator(\"testmodel.onnx\", verbose = 4)\n",
    "x_test = np.ones(WIDTH).astype(np.int8)\n",
    "res = sess.run([f\"Y_{DEPTH-1}\"], {\"X_0\": x_test})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -83 -118   -2   22]\n",
      " [  93  -70  -60  -29]\n",
      " [ 126  -34   36  -42]\n",
      " [  99  -74  104  123]]\n",
      "[-58 -69  30 -79]\n",
      "[[  82  125   24    8]\n",
      " [-113  -16   -6   55]\n",
      " [-118  -62    4   94]\n",
      " [ -62    6 -112 -117]]\n",
      "[102  75 103 -67]\n",
      "[[  29   67  -63 -127]\n",
      " [ -15   32  -37  -35]\n",
      " [ -63 -110   40   38]\n",
      " [  14   83   29   26]]\n",
      "[-73 -89  28 -85]\n"
     ]
    }
   ],
   "source": [
    "for init in onnx_model.graph.initializer:\n",
    "    print(onnx.numpy_helper.to_array(init).astype(np.int8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bespoke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
